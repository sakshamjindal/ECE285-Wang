{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 285 Assignment 1: Classification using Neural Network\n",
    "\n",
    "Now that you have developed and tested your model on the toy dataset set. It's time to get down and get dirty with a standard dataset such as cifar10. At this point, you will be using the provided training data to tune the hyper-parameters of your network such that it works with cifar10 for the task of multi-class classification.\n",
    "\n",
    "Important: Recall that now we have non-linear decision boundaries, thus we do not need to do one vs all classification. We learn a single non-linear decision boundary instead. Our non-linear boundaries (thanks to relu non-linearity) will take care of differentiating between all the classes\n",
    "\n",
    "TO SUBMIT: PDF of this notebook with all the required outputs and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ece285.utils.data_processing import get_cifar10_data\n",
    "from ece285.utils.evaluation import get_classification_accuracy\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10.0, 8.0)  # set default size of plots\n",
    "\n",
    "# For auto-reloading external modules\n",
    "# See http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use a subset of CIFAR10 for the assignment\n",
    "dataset = get_cifar10_data(\n",
    "    subset_train=5000,\n",
    "    subset_val=250,\n",
    "    subset_test=500,\n",
    ")\n",
    "\n",
    "print(dataset.keys())\n",
    "print(\"Training Set Data  Shape: \", dataset[\"x_train\"].shape)\n",
    "print(\"Training Set Label Shape: \", dataset[\"y_train\"].shape)\n",
    "print(\"Validation Set Data  Shape: \", dataset[\"x_val\"].shape)\n",
    "print(\"Validation Set Label Shape: \", dataset[\"y_val\"].shape)\n",
    "print(\"Test Set Data  Shape: \", dataset[\"x_test\"].shape)\n",
    "print(\"Test Set Label Shape: \", dataset[\"y_test\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset[\"x_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "x_val = dataset[\"x_val\"]\n",
    "y_val = dataset[\"y_val\"]\n",
    "x_test = dataset[\"x_test\"]\n",
    "y_test = dataset[\"y_test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import more utilies and the layers you have implemented\n",
    "from ece285.layers.sequential import Sequential\n",
    "from ece285.layers.linear import Linear\n",
    "from ece285.layers.relu import ReLU\n",
    "from ece285.layers.softmax import Softmax\n",
    "from ece285.layers.loss_func import CrossEntropyLoss\n",
    "from ece285.utils.optimizer import SGD\n",
    "from ece285.utils.dataset import DataLoader\n",
    "from ece285.utils.trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We show a few examples of training images from each class.\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "]\n",
    "samples_per_class = 7\n",
    "\n",
    "\n",
    "def visualize_data(dataset, classes, samples_per_class):\n",
    "    num_classes = len(classes)\n",
    "    for y, cls in enumerate(classes):\n",
    "        idxs = np.flatnonzero(y_train == y)\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs):\n",
    "            plt_idx = i * num_classes + y + 1\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            plt.imshow(dataset[idx])\n",
    "            plt.axis(\"off\")\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize the first 10 classes\n",
    "visualize_data(\n",
    "    x_train.reshape(5000, 3, 32, 32).transpose(0, 2, 3, 1),\n",
    "    classes,\n",
    "    samples_per_class,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3072\n",
    "hidden_size = 100  # Hidden layer size (Hyper-parameter)\n",
    "num_classes = 10  # Output\n",
    "\n",
    "# For a default setting we use the same model we used for the toy dataset.\n",
    "# This tells you the power of a 2 layered Neural Network. Recall the Universal Approximation Theorem.\n",
    "# A 2 layer neural network with non-linearities can approximate any function, given large enough hidden layer\n",
    "def init_model():\n",
    "    # np.random.seed(0) # No need to fix the seed here\n",
    "    l1 = Linear(input_size, hidden_size)\n",
    "    l2 = Linear(hidden_size, num_classes)\n",
    "\n",
    "    r1 = ReLU()\n",
    "    softmax = Softmax()\n",
    "    return Sequential([l1, r1, l2, softmax])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset with the dataloader class\n",
    "dataset = DataLoader(x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "net = init_model()\n",
    "optim = SGD(net, lr=0.01, weight_decay=0.01)\n",
    "loss_func = CrossEntropyLoss()\n",
    "epoch = 200  # (Hyper-parameter)\n",
    "batch_size = 200  # (Reduce the batch size if your computer is unable to handle it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer class by passing the above modules\n",
    "trainer = Trainer(\n",
    "    dataset, optim, net, loss_func, epoch, batch_size, validate_interval=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the trainer function we have already implemented for you. This trains the model for the given\n",
    "# hyper-parameters. It follows the same procedure as in the last ipython notebook you used for the toy-dataset\n",
    "train_error, validation_accuracy = trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the training and validation accuracies for the default hyper-parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ece285.utils.evaluation import get_classification_accuracy\n",
    "\n",
    "out_train = net.predict(x_train)\n",
    "acc = get_classification_accuracy(out_train, y_train)\n",
    "print(\"Training acc: \", acc)\n",
    "out_val = net.predict(x_val)\n",
    "acc = get_classification_accuracy(out_val, y_val)\n",
    "print(\"Validation acc: \", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug the training\n",
    "With the default parameters we provided above, you should get a validation accuracy of around ~0.2 on the validation set. This isn't very good.\n",
    "\n",
    "One strategy for getting insight into what's wrong is to plot the training loss function and the validation accuracies during optimization.\n",
    "\n",
    "Another strategy is to visualize the weights that were learned in the first layer of the network. In most neural networks trained on visual data, the first layer weights typically show some visible structure when visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss function and validation accuracies\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_error)\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "# plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(validation_accuracy, label=\"val\")\n",
    "plt.title(\"Classification accuracy history\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Classification accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ece285.utils.vis_utils import visualize_grid\n",
    "\n",
    "# Credits: http://cs231n.stanford.edu/\n",
    "\n",
    "# Visualize the weights of the network\n",
    "\n",
    "def show_net_weights(net):\n",
    "    W1 = net._modules[0].parameters[0]\n",
    "    W1 = W1.reshape(3, 32, 32, -1).transpose(3, 1, 2, 0)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype(\"uint8\"))\n",
    "    plt.gca().axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_net_weights(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune your hyperparameters (50%)\n",
    "\n",
    "**What's wrong?**. Looking at the visualizations above, we see that the loss is decreasing more or less linearly, which seems to suggest that the learning rate may be too low. Moreover, there is no gap between the training and validation accuracy, suggesting that the model we used has low capacity, and that we should increase its size. On the other hand, with a very large model we would expect to see more overfitting, which would manifest itself as a very large gap between the training and validation accuracy.\n",
    "\n",
    "**Tuning**. Tuning the hyperparameters and developing intuition for how they affect the final performance is a large part of using Neural Networks, so we want you to get a lot of practice. Below, you should experiment with different values of the various hyperparameters, including hidden layer size, learning rate, numer of training epochs, and regularization strength.\n",
    "\n",
    "**Approximate results**. You should be aim to achieve a classification accuracy of greater than 40% on the validation set. Our best network gets over 40% on the validation set.\n",
    "\n",
    "**Experiment**: You goal in this exercise is to get as good of a result on cifar10 as you can (40% could serve as a reference), with a fully-connected Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain your hyperparameter tuning process below.\n",
    "\n",
    "#### Your Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net_hyperparams = None  # store the best model into this\n",
    "\n",
    "#################################################################################\n",
    "# TODO: Tune hyperparameters using the validation set. Store your best trained  #\n",
    "# model hyperparams in best_net.                                                #\n",
    "#                                                                               #\n",
    "# To help debug your network, it may help to use visualizations similar to the  #\n",
    "# ones we used above; these visualizations will have significant qualitative    #\n",
    "# differences from the ones we saw above for the poorly tuned network.          #\n",
    "#                                                                               #\n",
    "# You are now free to test different combinations of hyperparameters to build   #\n",
    "# various models and test them according to the above plots and visualization   #\n",
    "\n",
    "\n",
    "# TODO: Show the above plots and visualizations for the default params (already #\n",
    "# done) and the best hyper-params you obtain. You only need to show this for 2  #\n",
    "# sets of hyper-params.                                                         #\n",
    "# You just need to store values for the hyperparameters in best_net_hyperparams #\n",
    "# as a list in the order\n",
    "# best_net_hyperparams = [lr, weight_decay, epoch, hidden_size]\n",
    "#################################################################################\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the training_error and validation_accuracy of the best network (5%)\n",
    "\n",
    "# TODO: visualize the weights of the best network (5%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on the test set (30%)\n",
    "When you are done experimenting, you should evaluate your final trained network on the test set; you should get above 35%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (best_net.predict(x_test) == y_test).mean()\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inline Question (10%)\n",
    "\n",
    "Now that you have trained a Neural Network classifier, you may find that your testing accuracy is much lower than the training accuracy. In what ways can we decrease this gap? Select all that apply.\n",
    "\n",
    "1. Train on a larger dataset.\n",
    "2. Add more hidden units.\n",
    "3. Increase the regularization strength.\n",
    "4. None of the above.\n",
    "\n",
    "#### Your Answer:\n",
    "\n",
    "#### Your Explanation:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
